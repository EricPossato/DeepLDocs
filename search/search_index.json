{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Template de Entrega","text":"Edi\u00e7\u00e3o <p>2025.1</p>"},{"location":"#eric-possato","title":"Eric Possato","text":"<p>Instru\u00e7\u00f5es</p> <p>Voc\u00eas devem utilizar este template como um bloco de notas para registrar o que foi feito e o que falta fazer. Voc\u00eas devem adicionar as informa\u00e7\u00f5es necess\u00e1rias. O template deve ser editado e atualizado a cada entrega, registrando assim a data de entrega e o que foi feito at\u00e9 o momento via Git.</p>"},{"location":"#entregas","title":"Entregas","text":"<ul> <li> Roteiro 1 - Data 23/02/2025</li> <li> Roteiro 2</li> <li> Roteiro 3</li> <li> Roteiro 4</li> <li> Projeto</li> </ul>"},{"location":"#diagramas","title":"Diagramas","text":"<p>Use o Mermaid para criar os diagramas de documenta\u00e7\u00e3o.</p> <p>Mermaid Live Editor</p> <pre><code>flowchart TD\n    Deployment:::orange --&gt;|defines| ReplicaSet\n    ReplicaSet --&gt;|manages| pod((Pod))\n    pod:::red --&gt;|runs| Container\n    Deployment --&gt;|scales| pod\n    Deployment --&gt;|updates| pod\n\n    Service:::orange --&gt;|exposes| pod\n\n    subgraph  \n        ConfigMap:::orange\n        Secret:::orange\n    end\n\n    ConfigMap --&gt; Deployment\n    Secret --&gt; Deployment\n    classDef red fill:#f55\n    classDef orange fill:#ffa500</code></pre>"},{"location":"#codigos","title":"C\u00f3digos","text":"De um arquivo remotoAnota\u00e7\u00f5es no c\u00f3digo main.yaml<pre><code>name: ci\non:\n  - push\n  - pull_request\n\n# Environment\nenv:\n  CI: true\n  PYTHON_VERSION: 3.12\n\n# Jobs to run\njobs:\n\n  # Build and deploy documentation site\n  deploy:\n    if: github.event_name != 'pull_request' &amp;&amp; github.ref == 'refs/heads/main'\n    runs-on: ubuntu-latest\n    steps:\n\n      # Checkout source form GitHub\n      - uses: actions/checkout@v4\n\n      # Install Python runtime and dependencies\n      - uses: actions/setup-python@v4\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n\n      # pip\n      - run: |\n          pip install -r requirements.txt\n\n      # deploy\n      - run: |\n          mkdocs gh-deploy --force\n</code></pre> compose.yaml<pre><code>name: app\n\n    db:\n        image: postgres:17\n        environment:\n            POSTGRES_DB: ${POSTGRES_DB:-projeto} # (1)!\n            POSTGRES_USER: ${POSTGRES_USER:-projeto}\n            POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-projeto}\n        ports:\n            - 5432:5432 #(2)!\n</code></pre> <ol> <li> <p>Caso a vari\u00e1vel de ambiente <code>POSTGRES_DB</code> n\u00e3o exista ou seja nula - n\u00e3o seja definida no arquivo <code>.env</code> - o valor padr\u00e3o ser\u00e1 <code>projeto</code>. Vide documenta\u00e7\u00e3o.</p> </li> <li> <p>Aqui \u00e9 feito um t\u00fanel da porta 5432 do container do banco de dados para a porta 5432 do host (no caso localhost). Em um ambiente de produ\u00e7\u00e3o, essa porta n\u00e3o deve ser exposta, pois ningu\u00e9m de fora do compose deveria acessar o banco de dados diretamente.</p> </li> </ol>"},{"location":"#exemplo-de-video","title":"Exemplo de v\u00eddeo","text":"<p>Lorem ipsum dolor sit amet</p>"},{"location":"#referencias","title":"Refer\u00eancias","text":"<p>Material for MkDocs</p>"},{"location":"exercise1/main/","title":"Exercise 1","text":"<p>Deadline and Submission</p> <p> 05.sep (friday)</p> <p> Commits until 23:59</p> <p> Individual</p> <p> Submission the GitHub Pages' Link (yes, only the link for pages) via insper.blackboard.com.</p> <p>Activity: Data Preparation and Analysis for Neural Networks</p> <p>This activity is designed to test your skills in generating synthetic datasets, handling real-world data challenges, and preparing data to be fed into neural networks.</p>"},{"location":"exercise1/main/#exercise-1","title":"Exercise 1","text":""},{"location":"exercise1/main/#exploring-class-separability-in-2d","title":"Exploring Class Separability in 2D","text":"<p>Understanding how data is distributed is the first step before designing a network architecture. In this exercise, you will generate and visualize a two-dimensional dataset to explore how data distribution affects the complexity of the decision boundaries a neural network would need to learn.</p>"},{"location":"exercise1/main/#instructions","title":"Instructions","text":"<ol> <li>Generate the Data: Create a synthetic dataset with a total of 400 samples, divided equally among 4 classes (100 samples each). Use a Gaussian distribution to generate the points for each class based on the following parameters:<ul> <li>Class 0: Mean = \\([2, 3]\\), Standard Deviation = \\([0.8, 2.5]\\)</li> <li>Class 1: Mean = \\([5, 6]\\), Standard Deviation = \\([1.2, 1.9]\\)</li> <li>Class 2: Mean = \\([8, 1]\\), Standard Deviation = \\([0.9, 0.9]\\)</li> <li>Class 3: Mean = \\([15, 4]\\), Standard Deviation = \\([0.5, 2.0]\\)</li> </ul> </li> <li>Plot the Data: Create a 2D scatter plot showing all the data points. Use a different color for each class to make them distinguishable.</li> <li>Analyze and Draw Boundaries:<ol> <li>Examine the scatter plot carefully. Describe the distribution and overlap of the four classes.</li> <li>Based on your visual inspection, could a simple, linear boundary separate all classes?</li> <li>On your plot, sketch the decision boundaries that you think a trained neural network might learn to separate these classes.</li> </ol> </li> </ol>"},{"location":"exercise1/main/#exercise-2","title":"Exercise 2","text":""},{"location":"exercise1/main/#non-linearity-in-higher-dimensions","title":"Non-Linearity in Higher Dimensions","text":"<p>Simple neural networks (like a Perceptron) can only learn linear boundaries. Deep networks excel when data is not linearly separable. This exercise challenges you to create and visualize such a dataset.</p>"},{"location":"exercise1/main/#instructions_1","title":"Instructions","text":"<ol> <li> <p>Generate the Data: Create a dataset with 500 samples for Class A and 500 samples for Class B. Use a multivariate normal distribution with the following parameters:</p> <ul> <li> <p>Class A:</p> <p>Mean vector:</p> \\[\\mu_A = [0, 0, 0, 0, 0]\\] <p>Covariance matrix:</p> \\[ \\Sigma_A = \\begin{pmatrix} 1.0 &amp; 0.8 &amp; 0.1 &amp; 0.0 &amp; 0.0 \\\\ 0.8 &amp; 1.0 &amp; 0.3 &amp; 0.0 &amp; 0.0 \\\\ 0.1 &amp; 0.3 &amp; 1.0 &amp; 0.5 &amp; 0.0 \\\\ 0.0 &amp; 0.0 &amp; 0.5 &amp; 1.0 &amp; 0.2 \\\\ 0.0 &amp; 0.0 &amp; 0.0 &amp; 0.2 &amp; 1.0 \\end{pmatrix} \\] </li> <li> <p>Class B:</p> <p>Mean vector:</p> \\[\\mu_B = [1.5, 1.5, 1.5, 1.5, 1.5]\\] <p>Covariance matrix:</p> \\[ \\Sigma_B = \\begin{pmatrix} 1.5 &amp; -0.7 &amp; 0.2 &amp; 0.0 &amp; 0.0 \\\\ -0.7 &amp; 1.5 &amp; 0.4 &amp; 0.0 &amp; 0.0 \\\\ 0.2 &amp; 0.4 &amp; 1.5 &amp; 0.6 &amp; 0.0 \\\\ 0.0 &amp; 0.0 &amp; 0.6 &amp; 1.5 &amp; 0.3 \\\\ 0.0 &amp; 0.0 &amp; 0.0 &amp; 0.3 &amp; 1.5 \\end{pmatrix} \\] </li> </ul> </li> <li> <p>Visualize the Data: Since you cannot directly plot a 5D graph, you must reduce its dimensionality.</p> <ul> <li>Use a technique like Principal Component Analysis (PCA) to project the 5D data down to 2 dimensions.</li> <li>Create a scatter plot of this 2D representation, coloring the points by their class (A or B).</li> </ul> </li> <li>Analyze the Plots:<ol> <li>Based on your 2D projection, describe the relationship between the two classes.</li> <li>Discuss the linear separability of the data. Explain why this type of data structure poses a challenge for simple linear models and would likely require a multi-layer neural network with non-linear activation functions to be classified accurately.</li> </ol> </li> </ol>"},{"location":"exercise1/main/#exercise-3","title":"Exercise 3","text":""},{"location":"exercise1/main/#preparing-real-world-data-for-a-neural-network","title":"Preparing Real-World Data for a Neural Network","text":"<p>This exercise uses a real dataset from Kaggle. Your task is to perform the necessary preprocessing to make it suitable for a neural network that uses the hyperbolic tangent (<code>tanh</code>) activation function in its hidden layers.</p>"},{"location":"exercise1/main/#instructions_2","title":"Instructions","text":"<ol> <li>Get the Data: Download the Spaceship Titanic dataset from Kaggle.</li> <li>Describe the Data:<ul> <li>Briefly describe the dataset's objective (i.e., what does the <code>Transported</code> column represent?).</li> <li>List the features and identify which are numerical (e.g., <code>Age</code>, <code>RoomService</code>) and which are categorical (e.g., <code>HomePlanet</code>, <code>Destination</code>).</li> <li>Investigate the dataset for missing values. Which columns have them, and how many?</li> </ul> </li> <li>Preprocess the Data: Your goal is to clean and transform the data so it can be fed into a neural network. The <code>tanh</code> activation function produces outputs in the range <code>[-1, 1]</code>, so your input data should be scaled appropriately for stable training.<ul> <li>Handle Missing Data: Devise and implement a strategy to handle the missing values in all the affected columns. Justify your choices.</li> <li>Encode Categorical Features: Convert categorical columns like <code>HomePlanet</code>, <code>CryoSleep</code>, and <code>Destination</code> into a numerical format. One-hot encoding is a good choice.</li> <li>Normalize/Standardize Numerical Features: Scale the numerical columns (e.g., <code>Age</code>, <code>RoomService</code>, etc.). Since the <code>tanh</code> activation function is centered at zero and outputs values in <code>[-1, 1]</code>, Standardization (to mean 0, std 1) or Normalization to a <code>[-1, 1]</code> range are excellent choices. Implement one and explain why it is a good practice for training neural networks with this activation function.</li> </ul> </li> <li>Visualize the Results:<ul> <li>Create histograms for one or two numerical features (like <code>FoodCourt</code> or <code>Age</code>) before and after scaling to show the effect of your transformation.</li> </ul> </li> </ol>"},{"location":"exercise1/main/#evaluation-criteria","title":"Evaluation Criteria","text":"<p>The deliverable for this activity consists of a report that includes:</p> <ol> <li>A brief description of your approach to each exercise.</li> <li>The code used to generate the datasets, preprocess the data, and create the visualizations. With comments explaining each step.</li> <li>The plots and visualizations requested in each exercise.</li> <li>Your analysis and answers to the questions posed in each exercise.</li> </ol> <p>Important Notes:</p> <ul> <li> <p>The deliverable must be submitted in the format specified: GitHub Pages. No other formats will be accepted. - there exists a template for the course that you can use to create your GitHub Pages - template;</p> </li> <li> <p>There is a strict policy against plagiarism. Any form of plagiarism will result in a zero grade for the activity and may lead to further disciplinary actions as per the university's academic integrity policies;</p> </li> <li> <p>The deadline for each activity is not extended, and it is expected that you complete them within the timeframe provided in the course schedule - NO EXCEPTIONS will be made for late submissions.</p> </li> <li> <p>AI Collaboration is allowed, but each student MUST UNDERSTAND and be able to explain all parts of the code and analysis submitted. Any use of AI tools must be properly cited in your report. ORAL EXAMS may require you to explain your work in detail.</p> </li> <li> <p>All deliverables for individual activities should be submitted through the course platform insper.blackboard.com.</p> </li> </ul> <p>Grade Criteria:</p> <p>Exercise 1 (3 points):</p> Criteria Description 1 pt Data is generated correctly and visualized in a clear scatter plot with proper labels and colors. 2 pts The analysis of class separability is accurate, and the proposed decision boundaries are logical and well-explained in the context of what a network would learn. <p>Exercise 2 (3 points):</p> Criteria Description 1 pt Data is generated correctly using the specified multivariate parameters. 1 pt Dimensionality reduction is applied correctly, and the resulting 2D projection is clearly plotted. 1 pt The analysis correctly identifies the non-linear relationship and explains why a neural network would be a suitable model. <p>Exercise 3 (4 points):</p> Criteria Description 1 pt The data is correctly loaded, and its characteristics are accurately described. 2 pts All preprocessing steps (handling missing data, encoding, and appropriate feature scaling for <code>tanh</code>) are implemented correctly and with clear justification for a neural network context. 1 pt Visualizations effectively demonstrate the impact of the data preprocessing."},{"location":"projeto/main/","title":"Projeto","text":"<p>Aqui vai toda a documenta\u00e7\u00e3o do projeto, incluindo o que j\u00e1 foi feito e o que falta fazer.</p>"},{"location":"thisdocumentation/main/","title":"This documentation","text":""},{"location":"thisdocumentation/main/#pre-requisitos","title":"Pr\u00e9-requisitos","text":"<p>Antes de come\u00e7ar, certifique-se de que voc\u00ea possui os seguintes pr\u00e9-requisitos instalados em seu sistema:</p> <ul> <li>Git: Para clonar o reposit\u00f3rio.</li> </ul>"},{"location":"thisdocumentation/main/#instalando-o-python","title":"Instalando o Python","text":"LinuxmacOSWindows <p>Instale o Python 3.8 ou superior.</p> <pre><code>sudo apt install python3 python3-venv python3-pip\npython3 --version\n</code></pre> <p>Instale o Python 3.8 ou superior.</p> <pre><code>brew install python\npython3 --version\n</code></pre> <p>Instale o Python 3.13 ou superior. Baixe o instalador do site oficial do Python (https://www.python.org/downloads/) e execute-o. Certifique-se de marcar a op\u00e7\u00e3o \"Add Python to PATH\" durante a instala\u00e7\u00e3o.</p> <pre><code>python --version\n</code></pre>"},{"location":"thisdocumentation/main/#usage","title":"Usage","text":"<p>Para utilizar o c\u00f3digo deste reposit\u00f3rio, siga as instru\u00e7\u00f5es a seguir:</p> <p>Clone ou fork este reposit\u00f3rio:</p> <pre><code>git clone &lt;URL_DO_REPOSITORIO&gt;\n</code></pre> <p>Crie um ambiente virtual do Python:</p> Linux/macOSWindows <pre><code>python3 -m venv env\n</code></pre> <pre><code>python -m venv env\n</code></pre> <p>Ative o ambiente virtual (voc\u00ea deve fazer isso sempre que for executar algum script deste reposit\u00f3rio):</p> Linux/macOSWindows <pre><code>source ./env/bin/activate\n</code></pre> <pre><code>.\\env\\Scripts\\activate\n</code></pre> <p>Instale as depend\u00eancias com:</p> Linux/macOSWindows <pre><code>python3 -m pip install -r requirements.txt --upgrade\n</code></pre> <pre><code>python -m pip install -r requirements.txt --upgrade\n</code></pre>"},{"location":"thisdocumentation/main/#deployment","title":"Deployment","text":"<p>O material utiliza o mkdocs para gerar a documenta\u00e7\u00e3o. Para visualizar a documenta\u00e7\u00e3o, execute o comando:</p> <pre><code>mkdocs serve -o\n</code></pre> <p>Para subir ao GitHub Pages, execute o comando:</p> <pre><code>mkdocs gh-deploy\n</code></pre> <p>Esse reposit\u00f3rio possui um workflow do GitHub Actions que executa o comando <code>mkdocs gh-deploy</code> sempre que houver um push na branch <code>main</code>. Assim, n\u00e3o \u00e9 necess\u00e1rio executar esse comando manualmente. Toda vez que voc\u00ea fizer um push na branch <code>main</code>, a documenta\u00e7\u00e3o ser\u00e1 atualizada automaticamente no GitHub Pages.</p> <p>Aviso 1</p> <p>Para que o github actions funcione corretamente, \u00e9 necess\u00e1rio que o reposit\u00f3rio esteja configurado para que o bot <code>github-actions[bot]</code> tenha permiss\u00e3o de escrita. Voc\u00ea pode verificar isso nas configura\u00e7\u00f5es do reposit\u00f3rio, na se\u00e7\u00e3o \"Actions\" e depois em \"General\". Certifique-se de que a op\u00e7\u00e3o \"Workflow permissions\" esteja definida como \"Read and write permissions\".</p> <p></p> <p>Aviso 2</p> <p>Depois de publicar, caso n\u00e3o consiga acessar a p\u00e1gina, verifique se o github pages est\u00e1 configurado corretamente. V\u00e1 at\u00e9 as configura\u00e7\u00f5es do reposit\u00f3rio, na se\u00e7\u00e3o \"Pages\" e verifique se a branch <code>gh-pages</code> est\u00e1 selecionada como fonte. Se n\u00e3o estiver, selecione-a e salve as altera\u00e7\u00f5es.</p> <p></p> <p>Pay Attention</p> <p>No arquivo '<code>mkdocs.yml</code>, a se\u00e7\u00e3o <code>site_url</code> deve estar configurada corretamente para o seu reposit\u00f3rio. Por exemplo, se o seu reposit\u00f3rio estiver em <code>https://github.com/usuario/repositorio</code>, a se\u00e7\u00e3o <code>site_url</code> deve ser:</p> <pre><code>site_url: https://usuario.github.io/repositorio\n</code></pre> <p>Tamb\u00e9m, certifique-se de que a se\u00e7\u00e3o <code>repo_url</code> esteja configurada corretamente para o seu reposit\u00f3rio. Por exemplo:</p> <pre><code>repo_url: https://github.com/usuario/repositorio\n</code></pre>"}]}